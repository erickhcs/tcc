{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P3hKX9S2d5sD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from IPython import display\n",
        "display.Image(\"image1.png\")\n",
        "\n",
        "mu = 4.3\n",
        "lamda = 1\n",
        "omega= 4.3\n",
        "alpha1= 0.7\n",
        "alpha2= 0.3\n",
        "alpha3= 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def generate_result_file(basePath,delay,jitter,loss):\n",
        "    try: \n",
        "        path1 = basePath + 'user1-segment.csv'\n",
        "        path2 = basePath + 'user1-session.csv'\n",
        "\n",
        "        data = pd.read_csv(path1)\n",
        "        data_final = pd.read_csv(path1)\n",
        "        data1 = pd.read_csv(path2)\n",
        "\n",
        "        # Fixing column name order\n",
        "        data1.rename(columns={' z1_bit': 'til_4k_z3'}, inplace=True)\n",
        "\n",
        "        data1.rename(columns={' z2_bit': ' z1_bit'}, inplace=True)\n",
        "\n",
        "        data1.rename(columns={' z3_bit': ' z2_bit'}, inplace=True)\n",
        "\n",
        "        data1.rename(columns={' til_4k_z3': ' z3_bit'}, inplace=True)\n",
        "\n",
        "        data_final.rename(columns={' z1_bit': 'til_4k_z3'}, inplace=True)\n",
        "\n",
        "        data_final.rename(columns={' z2_bit': ' z1_bit'}, inplace=True)\n",
        "\n",
        "        data_final.rename(columns={' z3_bit': ' z2_bit'}, inplace=True)\n",
        "\n",
        "        data_final.rename(columns={' til_4k_z3': ' z3_bit'}, inplace=True)\n",
        "\n",
        "        b1 = data.groupby('Zone')[' Bitrate'].sum()['Z1']\n",
        "        b2 = data.groupby('Zone')[' Bitrate'].sum()['Z2']\n",
        "        b3 = data.groupby('Zone')[' Bitrate'].sum()['Z3']\n",
        "\n",
        "        z1 = b1 - (mu * data1.iloc[0][' total_stall']) - (\n",
        "            lamda * data1.iloc[0][' qt_sw_z1']) - (omega * data1.iloc[0][' start_time'])\n",
        "        z1\n",
        "\n",
        "        z2 = b2 - (mu * data1.iloc[0][' total_stall']) - (\n",
        "            lamda * data1.iloc[0][' qt_sw_z2']) - (omega * data1.iloc[0][' start_time'])\n",
        "        z2\n",
        "\n",
        "        z3 = b3 - (mu * data1.iloc[0][' total_stall']) - (\n",
        "            lamda * data1.iloc[0][' qt_sw_z3']) - (omega * data1.iloc[0][' start_time'])\n",
        "        z3\n",
        "\n",
        "        # QoE (Ï•(V )) is modeled as a weighted linear sum of the QoE measurement per zone\n",
        "        QoE = (alpha1 * z1) + (alpha2 * z2) + (alpha3 * z3)\n",
        "        QoE\n",
        "\n",
        "        QoE1 = (alpha1 * z1) + (0.2 * z2) + (0.1 * z3)\n",
        "        QoE1\n",
        "\n",
        "        # Add QoE values in the dataframe as new column\n",
        "\n",
        "        data_final['QoE'] = QoE\n",
        "        data_final['QoE1'] = QoE1\n",
        "        data_final['Z1'] = z1\n",
        "        data_final['Z2'] = z2\n",
        "        data_final['Z3'] = z3\n",
        "\n",
        "        data_final['delay'] = delay\n",
        "        data_final['jitter'] = jitter\n",
        "        data_final['loss'] = loss\n",
        "\n",
        "        data_final.head(5)\n",
        "\n",
        "        path4 = basePath + 'user1-session1_QoE.csv'\n",
        "\n",
        "        data_final.to_csv(str(path4), index=False)\n",
        "\n",
        "        print('export csv ok')\n",
        "\n",
        "    except Exception as a:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rmBhMfrNzNEV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n",
            "export csv ok\n"
          ]
        },
        {
          "ename": "EmptyDataError",
          "evalue": "No columns to parse from file",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(basePath):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mgenerate_result_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasePath\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mgenerate_result_file\u001b[0;34m(basePath, delay, jitter, loss)\u001b[0m\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path1)\n\u001b[1;32m      6\u001b[0m data_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path1)\n\u001b[0;32m----> 7\u001b[0m data1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Fixing column name order\u001b[39;00m\n\u001b[1;32m     10\u001b[0m data1\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m z1_bit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtil_4k_z3\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
            "File \u001b[0;32mparsers.pyx:581\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
          ]
        }
      ],
      "source": [
        "for i in range(1, 5):\n",
        "    for j in range(1, 15):\n",
        "        for k in range(1, 8):\n",
        "            basePath = './final_experiment/2-43-136/scheduler/' + str(i) + '/client_' + str(k) + '/' + str(j) + '/'\n",
        "            if not os.path.exists(basePath):\n",
        "                continue\n",
        "            generate_result_file(basePath,'0','0','0')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
